Kubernetes -: Kubernetes is a production-grade, open-source platform that orchestrates the placement (scheduling) and execution 
************* of application containers within and across computer clusters.

1. Cluster
*************
1. Kubernetes coordinates a highly available cluster of computers that are connected to work as a single unit.
2. The abstractions in Kubernetes allow you to deploy containerized applications to a cluster without tying them specifically    to individual machines
3. To make use of this new model of deployment, applications need to be packaged in a way that decouples them from individual hosts: they need to be containerized.
4. Containerized applications are more flexible and available than in past deployment models, where applications were installed directly onto specific machines as packages deeply integrated into the host.
5. Kubernetes automates the distribution and scheduling of application containers across a cluster in a more efficient way.

A Kubernetes cluster consists of two types of resources: 1. The *Master* coordinates the cluster
														 2. *Nodes* are the workers that run applications

Masters manage the cluster and the nodes that are used to host the running applications.

Master -:
*********
1. The Master is responsible for managing the cluster.
2. The master coordinates all activities in your cluster, such as scheduling applications, maintaining applications' desired state, scaling applications, and rolling out new updates.

Node -:
********
1. A node is a VM or a physical computer that serves as a worker machine in a Kubernetes cluster.
2. Each node has a Kubelet, which is an agent for managing the node and communicating with the Kubernetes master
3. The node should also have tools for handling container operations, such as Docker or rkt.
4. A Kubernetes cluster that handles production traffic should have a minimum of three nodes.

Deploy Process-:
****************
1. When you deploy applications on Kubernetes, you tell the master to start the application containers.
2. The master schedules the containers to run on the cluster's nodes.
3. The nodes communicate with the master using the Kubernetes API, which the master exposes.
4. End users can also use the Kubernetes API directly to interact with the cluster.

The core of Kubernetes' control plane is the API server. The API server exposes an HTTP API that lets end users, different parts of your cluster, and external components communicate with one another.

The Kubernetes API lets you query and manipulate the state of objects in the Kubernetes API (for example: Pods, Namespaces, ConfigMaps, and Events).

Minikube is a lightweight Kubernetes implementation that creates a VM on your local machine and deploys a simple cluster 
*********
containing only one node.

The client version is the kubectl version; the server version is the Kubernetes version installed on the master.
kubectl version

kubectl cluster-info -> to view the cluster details

kubectl get nodes ->  To view the nodes in the cluster, This command shows all nodes that can be used to host our applications.


******************************************************************************************************************************

Deployment -:
**************
1. Once you have a running Kubernetes cluster, you can deploy your containerized applications on top of it. To do so, you      create a Kubernetes Deployment configuration.
2. The Deployment instructs Kubernetes how to create and update instances of your application.
3. Once you've created a Deployment, the Kubernetes master schedules the application instances included in that Deployment to run on individual Nodes in the cluster.

***********************************************
1. Once the application instances are created, a Kubernetes Deployment Controller continuously monitors those instances.
2. If the Node hosting an instance goes down or is deleted, the Deployment controller replaces the instance with an instance on another Node in the cluster.

**This provides a self-healing mechanism to address machine failure or maintenance.

Pod -:
******
A Kubernetes Pod is a group of one or more Containers, tied together for the purposes of administration and networking.

In a pre-orchestration world, installation scripts would often be used to start applications, but they did not allow recovery from machine failure.

By both creating your application instances and keeping them running across Nodes, Kubernetes Deployments provide a fundamentally different approach to application management.

Applications need to be packaged into one of the supported container formats in order to be deployed on Kubernetes
*********
Use the *kubectl create* command to create a Deployment that manages a Pod. The Pod runs a Container based on the provided Docker image

View the Deployment:
*******************
kubectl get deployments

View the Pod:
****************
kubectl get pods

View cluster events:
**********************
kubectl get events to see steps performed by underlying layer or the command

View the kubectl configuration:
*******************************
kubectl config view to view the YAML File

By default, the Pod is only accessible by its internal IP address within the Kubernetes cluster. To make the hello-node Container accessible from outside the Kubernetes virtual network, you have to expose the Pod as a Kubernetes Service.

The --type=LoadBalancer flag indicates that you want to expose your Service outside of the cluster.

View the Service you just created:
*************************************
kubectl get services


